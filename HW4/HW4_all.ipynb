{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW4_all.ipynb","provenance":[],"authorship_tag":"ABX9TyNqYYd4Hb3i1fyKeL1/sg3R"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wCcmjVwv1dEf"},"source":["#Imports and Data"]},{"cell_type":"code","metadata":{"id":"7dGBsJwg1QKy"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","from sklearn.metrics import accuracy_score\n","import sklearn.decomposition\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.metrics import confusion_matrix\n","from sklearn.linear_model import LogisticRegression\n","from time import time\n","import math as math"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LETSaE7S1Uv0"},"source":["fashion_mnist = keras.datasets.fashion_mnist;\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data();\n","\"\"\"\n","0\tT-shirt/top\n","1\tTrouser\n","2\tPullover\n","3\tDress\n","4\tCoat\n","5\tSandal\n","6\tShirt\n","7\tSneaker\n","8\tBag\n","9\tAnkle boot\n","\"\"\"\n","\n","label_names=['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal',\n","             'Shirt','Sneaker','Bag','Ankle boot']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wC3A-0bQ1YcD"},"source":["X_train = np.zeros([60000,784]) \n","for i in range(60000): \n","    img=train_images[i,:,:]\n","    X_train[i,:] = img.reshape([784])\n","\n","X_test = np.zeros([10000,784]) \n","for i in range(10000):\n","    img=test_images[i,:,:]\n","    X_test[i,:] = img.reshape([784])\n","\n","X_sub = X_train[:1000,:]\n","sub_labels = train_labels[:1000]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fOz8X6FD1m7C"},"source":["#1"]},{"cell_type":"code","metadata":{"id":"a0TfEplg1n2r"},"source":["def f(x):\n","    return (math.cos(x) - x)\n","\n","def df(x):\n","    return (-1*math.sin(x) - 1)\n","\n","def newtons_method(x0):\n","    xs=[x0]\n","    for i in range(5):\n","        xn=xs[-1]\n","        xs.append(xn - f(xn)/df(xn))\n","    return(xs)\n","\n","#xs = newtons_method(math.pi)\n","plt.plot(newtons_method(0),label = 'x0 = 0')\n","plt.plot(newtons_method(1),label = 'x0 = 1')\n","plt.plot(newtons_method(math.pi/2),label = 'x0=pi/2')\n","plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FaJ4N3XK1t4D"},"source":["#2"]},{"cell_type":"code","metadata":{"id":"bzAeBd3-1u-Q"},"source":["def f(x):\n","    return (x**4/4 - 3*x**3 + 7*x - 5)\n","\n","def df(x):\n","    return (x**3 - 9*x**2 + 7)\n","\n","def newtons_method(x0):\n","    xs=[x0]\n","    for i in range(5):\n","        xn=xs[-1]\n","        xs.append(xn - f(xn)/df(xn))\n","    return(xs)\n","\n","def grad_descent(x,nu):\n","    xs = [x]\n","    for i in range(30):\n","        xn=xs[-1]\n","        xs.append(xn - nu*df(xn))\n","    return(xs)\n","\n","plt.plot(grad_descent(0,.01),label = 'learning rate .01')\n","plt.plot(grad_descent(0,.05),label = 'learning rate .05')\n","plt.plot(grad_descent(0,.1),label = 'learning rate .1')\n","plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VVaM5LV517f2"},"source":["#3"]},{"cell_type":"code","metadata":{"id":"CERJNK7B18xW"},"source":["col_means = np.mean(X_train, axis = 0)\n","X_tilda = X_train - col_means\n","X_test_centered = X_test - col_means\n","\n","k=190\n","PCA = sklearn.decomposition.PCA(n_components = k)\n","PCA.fit(X_tilda)\n","Y_train = PCA.transform(X_tilda)\n","Y_test = PCA.transform(X_test_centered)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zA7O-bMu2LEs"},"source":["start1 = time()\n","#fits models\n","for i in range(10):\n","    for j in range(i+1,10):\n","        globals()['ovo'+str(i)+str(j)] = LogisticRegression(penalty='none')\n","        globals()['ovo'+str(i)+str(j)].fit(Y_train[(train_labels==i) | (train_labels==j),], \n","                                           train_labels[(train_labels==i) | (train_labels==j)]);\n","\n","#predicts\n","pred_mat = np.zeros([Y_test.shape[0],45])\n","col = 0\n","for i in range(10):\n","    for j in range(i+1,10):\n","        \n","        pred_mat[:,col] = globals()['ovo'+str(i)+str(j)].predict(Y_test)\n","        col+=1\n","pred_mat = pred_mat.astype('int')\n","\n","#print(pred_mat[0,:])\n","preds1=np.zeros([pred_mat.shape[0]])\n","for i in range(pred_mat.shape[0]):\n","    \n","    preds1[i] = np.argmax(np.bincount(pred_mat[i,:]))\n","\n","score1 = accuracy_score(y_true = test_labels, y_pred = preds1)\n","score1\n","end1 = time()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JwLdepgU2NJm"},"source":["#1v1, 1 vs rest, multinomial\n","start2 = time()\n","logreg2 = LogisticRegression(penalty='none', multi_class = 'ovr',max_iter = 500)\n","logreg2.fit(Y_train, train_labels)\n","preds2 = logreg2.predict(Y_test)\n","score2 = accuracy_score(y_true = test_labels, y_pred = preds2)\n","end2 = time()\n","\n","start3=time()\n","logreg3 = LogisticRegression(penalty='none', multi_class = 'multinomial',max_iter=500).fit(Y_train, train_labels)\n","preds3 = logreg3.predict(Y_test)\n","score3 = accuracy_score(y_true = test_labels, y_pred = preds3)\n","end3 = time()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZPNLyGxW2PI1"},"source":["start4 = time()\n","lda = LinearDiscriminantAnalysis()\n","lda.fit(Y_train,train_labels)\n","preds4 = lda.predict(Y_test)\n","score4=accuracy_score(y_true=test_labels, y_pred=preds4)\n","end4 = time()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l5yYqTwD2S5h"},"source":["print(score1)\n","print(score2)\n","print(score3)\n","print(score4)\n","print(end1-start1)\n","print(end2-start2)\n","print(end3-start3)\n","print(end4-start4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TmJpq9m45iA6"},"source":["#4"]},{"cell_type":"code","metadata":{"id":"ghfrPsGg5k8W"},"source":["start =time()\n","logreg = LogisticRegression(penalty='l1', multi_class = 'multinomial',max_iter=500,solver='saga').fit(X_train, train_labels)\n","preds = logreg.predict(X_test)\n","score = accuracy_score(y_true = test_labels, y_pred = preds)\n","end = time()\n","\n","print(score)\n","print(end-start)"],"execution_count":null,"outputs":[]}]}